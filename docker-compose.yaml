version: '3.8'

services:
  agent_classifier_app:
    build:
      context: .
      dockerfile: Dockerfile.app
    container_name: agent_classifier_app
    #ports:
    #  - "9000:9000"  # Expose the port Waitress is running on
    volumes:
      - shared_data:/app/shared_data
    networks:
      - my_network
    depends_on:
      - ollama_server

 
  ollama_server:
    build:
      context: .
      dockerfile: Dockerfile.ollama.llama3.2
    mem_limit: 8g
    ports: [] 
    environment:
      OLLAMA_HOST: "0.0.0.0:11434"
    volumes:
      - ollama_data:/root/.ollama
      - shared_data:/shared_data
    networks:
      - my_network
    entrypoint: [ "/bin/bash", "/entrypoint.sh" ]

  audio_server:
    build:
      context: .
      dockerfile: Dockerfile.audio_server
    container_name: audio_server
    ports:
      - "80:8000"  
    networks:
      - my_network
    depends_on:
      - agent_classifier_app

volumes:
  shared_data:
  ollama_data:


networks:
  my_network:
